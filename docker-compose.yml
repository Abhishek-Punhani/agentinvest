services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: auth_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: auth_user
      POSTGRES_PASSWORD: auth_password
      POSTGRES_DB: auth_db
      POSTGRES_INITDB_ARGS: "-E UTF8"
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U auth_user -d auth_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - agentInvest

  # Redis Cache & Queue
  redis:
    image: redis:7-alpine
    container_name: auth_redis
    restart: unless-stopped
    command: >
      sh -c "redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru &
             sleep 2 &&
             redis-cli KEYS '*lock*' | xargs -r redis-cli DEL &&
             redis-cli KEYS '*timestamp*' | xargs -r redis-cli DEL &&
             redis-cli KEYS 'redbeat:*' | xargs -r redis-cli DEL &&
             echo 'Auth Redis: Cleared locks and timestamps' &&
             wait"
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - agentInvest

  # Portfolio PostgreSQL Database
  portfolio_postgres:
    image: postgres:16-alpine
    container_name: portfolio_postgres
    restart: unless-stopped
    command: postgres -c max_connections=200 -c shared_buffers=512MB -c idle_in_transaction_session_timeout=300000 -c tcp_keepalives_idle=60 -c tcp_keepalives_interval=10 -c tcp_keepalives_count=6
    environment:
      POSTGRES_USER: portfolio_user
      POSTGRES_PASSWORD: portfolio_password
      POSTGRES_DB: portfolio_db
      POSTGRES_INITDB_ARGS: "-E UTF8"
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5434:5432"
    volumes:
      - portfolio_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U portfolio_user -d portfolio_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - agentInvest

  # Portfolio Redis Cache & Queue
  portfolio_redis:
    image: redis:7-alpine
    container_name: portfolio_redis
    restart: unless-stopped
    command: >
      sh -c "redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru &
             sleep 2 &&
             redis-cli KEYS '*lock*' | xargs -r redis-cli DEL &&
             redis-cli KEYS '*timestamp*' | xargs -r redis-cli DEL &&
             redis-cli KEYS 'redbeat:*' | xargs -r redis-cli DEL &&
             echo 'Portfolio Redis: Cleared locks and timestamps' &&
             wait"
    ports:
      - "6381:6379"
    volumes:
      - portfolio_redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - agentInvest

  # Arize Phoenix (LLM Observability & Tracing)
  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: phoenix
    restart: unless-stopped
    environment:
      # Authentication Configuration
      PHOENIX_ENABLE_AUTH: "true"
      PHOENIX_SECRET: "3413f9a7735bb780c6b8e4db7d946a492b64d26112a955cdea6a797f4c833593"
      PHOENIX_DEFAULT_ADMIN_INITIAL_PASSWORD: "Admin@2024Secure"
      PHOENIX_USE_SECURE_COOKIES: "true"
      # Optional: Configure trusted origins for CSRF protection (adjust to your domain)
      # PHOENIX_CSRF_TRUSTED_ORIGINS: "http://localhost:3000,https://yourdomain.com"
      # Token expiry settings (optional, using reasonable defaults)
      PHOENIX_ACCESS_TOKEN_EXPIRY_MINUTES: "60"
      PHOENIX_REFRESH_TOKEN_EXPIRY_MINUTES: "10080"  # 7 days
      # Storage
      PHOENIX_WORKING_DIR: "/phoenix-data"
    ports:
      - "6006:6006"  # UI and OTLP HTTP collector
      - "4317:4317"  # OTLP gRPC collector
    volumes:
      - phoenix_data:/phoenix-data
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:6006"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - agentInvest

  # Auth Server Application
  auth_server:
    image: auth_server:latest
    container_name: auth_server
    restart: unless-stopped
    build:
      context: .
      dockerfile: apps/auth_server/Dockerfile
    env_file:
      - docker.env
      - apps/auth_server/docker.env
    working_dir: /app/apps/auth_server
    command: >
      sh -c "pnpm prisma generate --schema ../../shared/prisma/schema.prisma &&
             pnpm prisma db push --schema ../../shared/prisma/schema.prisma &&
             pnpm run start"
    ports:
      - "4000:4000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - agentInvest

  # Notification Server (Kafka Consumer -> Redis Publisher)
  notification_server:
    image: notification_server:latest
    container_name: notification_server
    restart: unless-stopped
    build:
      context: .
      dockerfile: apps/notification_server/Dockerfile
    env_file:
      - docker.env
      - apps/notification_server/docker.env
    working_dir: /app
    command: >
      sh -c "cd apps/notification_server && pnpm prisma generate --schema /app/shared/prisma/schema.prisma &&
             pnpm prisma db push --schema /app/shared/prisma/schema.prisma --accept-data-loss &&
             node -r tsconfig-paths/register dist/apps/notification_server/src/index.js"
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'node.*index.js' > /dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - agentInvest

  # Portfolio Server (FastAPI)
  portfolio_server:
    image: portfolio_server:latest
    container_name: portfolio_server
    restart: unless-stopped
    build:
      context: .
      dockerfile: apps/portfolio-server/Dockerfile
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      KAFKA_CLIENT_ID: portfolio-server
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               uvicorn main:app --host 0.0.0.0 --port 8000"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    ports:
      - "8000:8000"
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - Trading Queue (Real-time trade execution)
  portfolio_celery_trading:
    image: portfolio_server:latest
    container_name: portfolio_celery_trading
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9101"
      WORKER_NAME: trading@docker
      KAFKA_CLIENT_ID: portfolio-celery-trading
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q trading --concurrency=4 --hostname=trading@%h --max-tasks-per-child=100 --prefetch-multiplier=1"
    ports:
      - "9101:9101"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
      - ./quant-stream:/app/quant-stream
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - NSE Pipeline Queue (NSE filings - dedicated, 1 worker)
  portfolio_celery_nse_pipeline:
    image: portfolio_server:latest
    container_name: portfolio_celery_nse_pipeline
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9102"
      WORKER_NAME: nse_pipeline@docker
      KAFKA_CLIENT_ID: portfolio-celery-nse-pipeline
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q nse_pipeline --concurrency=1 --hostname=nse_pipeline@%h --max-tasks-per-child=10 --prefetch-multiplier=1"
    ports:
      - "9102:9102"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - News Pipeline Queue (News sentiment - dedicated, 1 worker)
  portfolio_celery_news_pipeline:
    image: portfolio_server:latest
    container_name: portfolio_celery_news_pipeline
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9108"
      WORKER_NAME: news_pipeline@docker
      KAFKA_CLIENT_ID: portfolio-celery-news-pipeline
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q news_pipeline,pipelines --concurrency=1 --hostname=news_pipeline@%h --max-tasks-per-child=10 --prefetch-multiplier=1"
    ports:
      - "9108:9108"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - Low Risk Pipeline Queue (Low-risk stock selection - dedicated, 1 worker, long-running)
  portfolio_celery_low_risk:
    image: portfolio_server:latest
    container_name: portfolio_celery_low_risk
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9107"
      WORKER_NAME: low_risk@docker
      KAFKA_CLIENT_ID: portfolio-celery-low-risk
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q low_risk_pipeline --concurrency=1 --hostname=low_risk@%h --max-tasks-per-child=5 --prefetch-multiplier=1"
    ports:
      - "9107:9107"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - Allocation Queue (Portfolio allocation & rebalancing)
  portfolio_celery_allocation:
    image: portfolio_server:latest
    container_name: portfolio_celery_allocation
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9103"
      WORKER_NAME: allocation@docker
      KAFKA_CLIENT_ID: portfolio-celery-allocation
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q allocations --concurrency=2 --hostname=allocation@%h --max-tasks-per-child=100 --prefetch-multiplier=1"
    ports:
      - "9103:9103"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - Market Queue (Market data & token management)
  portfolio_celery_market:
    image: portfolio_server:latest
    container_name: portfolio_celery_market
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9104"
      WORKER_NAME: market@docker
      KAFKA_CLIENT_ID: portfolio-celery-market
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q market,tokens --concurrency=4 --hostname=market@%h --max-tasks-per-child=500 --prefetch-multiplier=1"
    ports:
      - "9104:9104"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - General Queue (Misc tasks, risk, orders)
  portfolio_celery_general:
    image: portfolio_server:latest
    container_name: portfolio_celery_general
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9105"
      WORKER_NAME: general@docker
      KAFKA_CLIENT_ID: portfolio-celery-general
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q general,risk,orders,pipelines --concurrency=4 --hostname=general@%h --max-tasks-per-child=200 --prefetch-multiplier=1"
    ports:
      - "9105:9105"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
      - ./quant-stream:/app/quant-stream
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - Streaming Queue (Long-running streaming tasks)
  portfolio_celery_streaming:
    image: portfolio_server:latest
    container_name: portfolio_celery_streaming
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9106"
      WORKER_NAME: streaming@docker
      KAFKA_CLIENT_ID: portfolio-celery-streaming
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q streaming --concurrency=1 --hostname=streaming@%h --max-tasks-per-child=1 --prefetch-multiplier=1 --without-heartbeat --without-gossip"
    ports:
      - "9106:9106"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Worker - Regime Queue (Regime detection & rebalancing sweeps)
  portfolio_celery_regime:
    image: portfolio_server:latest
    container_name: portfolio_celery_regime
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      CELERY_WORKER_RUNNING: "1"
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: "9109"
      WORKER_NAME: regime@docker
      KAFKA_CLIENT_ID: portfolio-celery-regime
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app worker --loglevel=info -Q regime --concurrency=1 --hostname=regime@%h --max-tasks-per-child=10 --prefetch-multiplier=1"
    ports:
      - "9109:9109"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Celery Beat (Scheduler for periodic tasks)
  portfolio_celery_beat:
    image: portfolio_server:latest
    container_name: portfolio_celery_beat
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      KAFKA_CLIENT_ID: portfolio-celery-beat
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               celery -A celery_app:celery_app beat --loglevel=info -S redbeat.RedBeatScheduler"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
      portfolio_celery_trading:
        condition: service_started
      portfolio_celery_nse_pipeline:
        condition: service_started
      portfolio_celery_news_pipeline:
        condition: service_started
      portfolio_celery_low_risk:
        condition: service_started
      portfolio_celery_allocation:
        condition: service_started
      portfolio_celery_market:
        condition: service_started
      portfolio_celery_general:
        condition: service_started
      portfolio_celery_streaming:
        condition: service_started
      portfolio_celery_regime:
        condition: service_started
    networks:
      - agentInvest

  # Flower (Celery monitoring dashboard with Prometheus metrics)
  flower:
    image: portfolio_server:latest
    container_name: flower
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      FLOWER_PERSISTENT: "true"
      FLOWER_PURGE_OFFLINE_WORKERS: "60"
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               pip install flower &&
               celery -A celery_app:celery_app flower --port=5555 --basic_auth=admin:admin123 --broker_api=redis://portfolio_redis:6379/0 --prometheus_enable=True"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    ports:
      - "5555:5555"
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:5555/healthcheck || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
      portfolio_celery_trading:
        condition: service_started
    networks:
      - agentInvest
    profiles:
      - monitoring

  # Celery Exporter (Primary Prometheus metrics source for Celery)
  celery-exporter:
    image: danihodovic/celery-exporter:latest
    container_name: celery-exporter
    restart: unless-stopped
    environment:
      CE_BROKER_URL: "redis://portfolio_redis:6379/0"
      CE_LISTEN_ADDRESS: "0.0.0.0:9540"
      CE_NAMESPACE: "celery"
      CE_MAX_TASKS: "10000"
      CE_RETRY_INTERVAL: "5"
    ports:
      - "9540:9540"
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:9540/metrics || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    depends_on:
      portfolio_redis:
        condition: service_healthy
      portfolio_celery_trading:
        condition: service_started
    networks:
      - agentInvest
    profiles:
      - monitoring

  # Frontend (Next.js)
  frontend:
    image: frontend_web:latest
    container_name: frontend_web
    restart: unless-stopped
    build:
      context: .
      dockerfile: apps/frontend/Dockerfile
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-https://auth.agentinvest.space}
        NEXT_PUBLIC_AUTH_BASE_URL: ${NEXT_PUBLIC_AUTH_BASE_URL:-https://auth.agentinvest.space/api/auth}
        NEXT_PUBLIC_PORTFOLIO_API_URL: ${NEXT_PUBLIC_PORTFOLIO_API_URL:-https://portfolio.agentinvest.space}
        NEXT_PUBLIC_PORTFOLIO_SERVER_URL: ${NEXT_PUBLIC_PORTFOLIO_SERVER_URL:-https://portfolio.agentinvest.space}
        NEXT_PUBLIC_ALPHACOPILOT_URL: ${NEXT_PUBLIC_ALPHACOPILOT_URL:-https://alphacopilot.agentinvest.space}
        NEXT_PUBLIC_WS_URL: ${NEXT_PUBLIC_WS_URL:-ws://localhost:4001}
    env_file:
      - docker.env
      - apps/frontend/docker.env
    working_dir: /app/apps/frontend
    command: >
      sh -c "pnpm --filter frontend exec next start -H 0.0.0.0 -p ${PORT:-3000}"
    # NOTE: No volumes mounted for production - use the built .next from the image
    ports:
      - "3000:3000"
    depends_on:
      auth_server:
        condition: service_started
      redis:
        condition: service_healthy
    networks:
      - agentInvest

  # Apache Kafka (KRaft mode)
  kafka:
    image: apache/kafka:3.8.0
    container_name: pathway-kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 20s
    networks:
      - agentInvest

  # AlphaCopilot Server (FastAPI - AI Trading Copilot with Quant-Stream Library)
  alphacopilot_server:
    image: alphacopilot_server:latest
    container_name: alphacopilot_server
    restart: unless-stopped
    build:
      context: .
      dockerfile: apps/alphacopilot-server/Dockerfile
    env_file:
      - docker.env
      - apps/alphacopilot-server/docker.env
    environment:
      PYTHONPATH: /app:/app/shared/py:/app/quant-stream:/app/apps/alphacopilot-server
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
    working_dir: /app/apps/alphacopilot-server
    command: python -m uvicorn main:app --host 0.0.0.0 --port 8069
    ports:
      - "8069:8069"
    volumes:
      # Mount source code for development
      - ./apps/alphacopilot-server:/app/apps/alphacopilot-server
      - ./shared:/app/sharedx
      # Mount data directory for market data (not baked into image)
      - ./quant-stream/.data:/app/quant-stream/.data:ro
      - ./data:/app/data
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8069/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - agentInvest

  # AlphaCopilot Celery Worker (Backtest Processing)
  alphacopilot_celery:
    image: alphacopilot_server:latest
    container_name: alphacopilot_celery
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/alphacopilot-server/docker.env
    environment:
      PYTHONPATH: /app:/app/shared/py:/app/quant-stream:/app/apps/alphacopilot-server
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
    working_dir: /app/quant-stream
    command: celery -A quant_stream.mcp_server.core.celery_config worker --loglevel=info -Q backtest --concurrency=2 --hostname=backtest@%h --max-tasks-per-child=50
    volumes:
      # Mount data directory for market data (not baked into image)
      - ./quant-stream/.data:/app/quant-stream/.data:ro
      - ./data:/app/data
    depends_on:
      portfolio_redis:
        condition: service_healthy
      alphacopilot_server:
        condition: service_started
    networks:
      - agentInvest

  # Optional: Redis Commander (Redis GUI)
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redis_commander
    restart: unless-stopped
    environment:
      REDIS_HOSTS: auth:redis:6379,portfolio:portfolio_redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis
      - portfolio_redis
    networks:
      - agentInvest
    profiles:
      - debug

  # Optional: pgAdmin (PostgreSQL GUI)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - postgres
      - portfolio_postgres
    networks:
      - agentInvest
    profiles:
      - debug

  # Prometheus (Metrics Collection)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./docker_manifests/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./devops/monitoring/alert-rules.yml:/etc/prometheus/alert-rules.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    networks:
      - agentInvest
    profiles:
      - monitoring

  # Grafana (Visualization Dashboard)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3001
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker_manifests/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml:ro
      - ./devops/monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./devops/monitoring/celery-dashboard.json:/var/lib/grafana/dashboards/celery-dashboard.json:ro
      - ./devops/monitoring/celery-detailed-dashboard.json:/var/lib/grafana/dashboards/celery-detailed-dashboard.json:ro
    depends_on:
      - prometheus
      - loki
    networks:
      - agentInvest
    profiles:
      - monitoring

  # Redis Exporter (Optional - for Redis metrics)
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    restart: unless-stopped
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://portfolio_redis:6379
    depends_on:
      - portfolio_redis
    networks:
      - agentInvest
    profiles:
      - monitoring

  # PostgreSQL Exporter (Optional - for DB metrics)
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    restart: unless-stopped
    ports:
      - "9187:9187"
    environment:
      - DATA_SOURCE_NAME=postgresql://portfolio_user:portfolio_password@portfolio_postgres:5432/portfolio_db?sslmode=disable
    depends_on:
      portfolio_postgres:
        condition: service_healthy
    networks:
      - agentInvest
    profiles:
      - monitoring

  # Loki (Log Aggregation)
  loki:
    image: grafana/loki:latest
    container_name: loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./docker_manifests/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - agentInvest
    profiles:
      - monitoring

  # Promtail (Log Shipping to Loki)
  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    restart: unless-stopped
    volumes:
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./docker_manifests/promtail-config.yml:/etc/promtail/config.yml:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - agentInvest
    profiles:
      - monitoring

  # Portainer (Docker Management UI)
  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    restart: unless-stopped
    ports:
      - "9443:9443"
      - "8100:8000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    networks:
      - agentInvest

  # Pathway Order Monitor - Real-time TP/SL monitoring (Reactive Pathway pipeline)
  pathway_order_monitor:
    image: portfolio_server:latest
    container_name: pathway_order_monitor
    restart: unless-stopped
    env_file:
      - docker.env
      - apps/portfolio-server/docker.env
    environment:
      PYTHONPATH: /app:/app/apps/portfolio-server:/app/shared/py:/app/middleware/py
      PATHWAY_ORDER_MONITOR_ENABLED: "true"
      REDIS_HOST: portfolio_redis
      REDIS_PORT: "6379"
      PORTFOLIO_SERVER_URL: http://portfolio_server:8000
      KAFKA_CLIENT_ID: pathway-order-monitor
      COLLECTOR_ENDPOINT: http://phoenix:6006/v1/traces
    working_dir: /app/apps/portfolio-server
    command: >
      bash -c "cp /app/apps/portfolio-server/docker.env /app/apps/portfolio-server/.env 2>/dev/null || true &&
               python -m prisma generate &&
               until python -m prisma db push --accept-data-loss; do
                 echo 'Waiting for Postgres...';
                 sleep 2;
               done &&
               echo 'ðŸš€ Starting Pathway Order Monitor (Reactive TP/SL)...' &&
               python -m workers.pathway_order_monitor"
    volumes:
      - ./apps/portfolio-server:/app/apps/portfolio-server
      - ./shared:/app/shared
      - ./middleware:/app/middleware
      - ./scripts:/app/scripts
    depends_on:
      portfolio_postgres:
        condition: service_healthy
      portfolio_redis:
        condition: service_healthy
      portfolio_server:
        condition: service_started
    networks:
      - agentInvest

networks:
  agentInvest:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  portfolio_postgres_data:
    driver: local
  portfolio_redis_data:
    driver: local
  pgadmin_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
  portainer_data:
    driver: local
  phoenix_data:
    driver: local
